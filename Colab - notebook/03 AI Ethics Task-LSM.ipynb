{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"16MtbKojhDkew9dOIGCvgei5ZTu5KqS3V","timestamp":1697553388133}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# AI Ethics. Practical Task\n","\n","## AI Risks Identification Tool\n","\n","Let's create an interactive and structured *AI Risks Identification Tool* that allows users to categorize the identified risks and provides a summary of the risks under each category. We'll use dictionaries and lists to organize the data.\n","\n","Below are the descriptions of the functions which will be used in the AI Risks Identification Tool:\n","\n","`get_risks_and_categories` - This function asks users to input the appropriate category of the potential risks associated with the usage of AI in everyday life. It prompts the user to enter risks and their corresponding categories iteratively until all the elements from `risks_list` will be passed. The risks and categories (entered by the user) are stored in a list of lists, where each category is 0 element of inner list, and the corresponding risks is stored as a 1 element of inner list (eg. `[[category0, risk0], [category1, risk1]], ...`).\n","\n","- Parameters: This function takes `risks_list` parameter.\n","- Returns: This function returns `risks_categories` - a list of lists  containing the risks and categories.\n","\n","`identify_risks()` - This function allows users to identify and categorize potential risks associated with the usage of AI in everyday life. The risks and categories are stored in a dictionary, where each category is a key, and the corresponding risks are stored in a list under that key.\n","\n","- Parameters: This function takes `risks_categories` parameter.\n","- Returns: This function returns a dictionary containing the categorized risks. The keys of the dictionary are the categories, and the values are lists of risks associated with each category.\n","\n","`display_risks_summary(risks)` - This function displays a summary of the identified AI risks under each category. It takes the categorized risks dictionary as input and prints the risks in a user-friendly format.\n","\n","- Parameters: `risks (dict)` - A dictionary containing categorized risks. The keys are the categories, and the values are lists of risks associated with each category.\n","- Returns: This function does not return any value. It simply prints the summary of identified AI risks.\n","\n","The `identify_risks()` function organizes the entered risks into a dictionary to keep track of the different risk categories. The `display_risks_summary()` function then takes this dictionary as input and presents a clear summary of the identified AI risks under each category.\n","\n","These functions enable users to interactively explore and categorize AI risks, making it easier to comprehend the various challenges and concerns associated with the use of AI in everyday life.\n"],"metadata":{"id":"J4wHqKTAknKf"}},{"cell_type":"markdown","source":["You may use these sample data to test your code\n","\n","```\n","Privacy concerns: AI-powered devices may collect personal data, raising concerns about how this data is stored and used.\n","Category: Privacy\n","\n","Security vulnerabilities: AI systems could be susceptible to cyberattacks, leading to unauthorized access to personal information.\n","Category: Security\n","\n","Bias in AI algorithms: AI algorithms might inadvertently perpetuate biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n","Category: Fairness\n","\n","Bias in AI algorithms may cause biased loan approvals for certain demographic groups.\n","Category: Fairness\n","\n","AI system malfunctioning may result in incorrect medical diagnoses.\n","Category: Safety\n","\n","AI-driven job automation may lead to unemployment and job displacement.\n","Category: Social Impact\n","```\n"],"metadata":{"id":"Dyhl1aJivsnz"}},{"cell_type":"code","source":["pip install git+https://github.com/mehalyna/cooltest.git"],"metadata":{"id":"gBCcpv4F0dJf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697987104592,"user_tz":-180,"elapsed":9325,"user":{"displayName":"lee scriber","userId":"13285270051983739409"}},"outputId":"373c20c4-5435-4f6d-8341-7d6fa4798561"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/mehalyna/cooltest.git\n","  Cloning https://github.com/mehalyna/cooltest.git to /tmp/pip-req-build-_17frijy\n","  Running command git clone --filter=blob:none --quiet https://github.com/mehalyna/cooltest.git /tmp/pip-req-build-_17frijy\n","  Resolved https://github.com/mehalyna/cooltest.git to commit f4c950440e06f6870bf813c9e2f1b253f1f497ba\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from cooltest==26.18) (1.23.5)\n","Building wheels for collected packages: cooltest\n","  Building wheel for cooltest (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cooltest: filename=cooltest-26.18-py3-none-any.whl size=5423 sha256=cf83580255bc0bcc32e75e5c90b3c4cca117981eca6c9e664b6af86f7727146f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-jiublefa/wheels/5f/d0/08/46fba8323b078d91da2d05922a680d9728e94d53b453a8dd79\n","Successfully built cooltest\n","Installing collected packages: cooltest\n","Successfully installed cooltest-26.18\n"]}]},{"cell_type":"code","source":["from cooltest.test_cool_4 import *"],"metadata":{"id":"nj87-lSz0eL6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697987117141,"user_tz":-180,"elapsed":10554,"user":{"displayName":"lee scriber","userId":"13285270051983739409"}},"outputId":"07d948e4-2361-4f09-df70-6fa0f0064c29"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Pass\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"LsDCRjINfw5U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697987220610,"user_tz":-180,"elapsed":27717,"user":{"displayName":"lee scriber","userId":"13285270051983739409"}},"outputId":"1a4e5628-76ef-486b-e489-f93d6411c577"},"outputs":[{"output_type":"stream","name":"stdout","text":["Risk Task Passed\n","\n","Welcome to the AI Risks Identification Tool!\n","Enter the category of each risk:\n","Category for 'Privacy concerns: AI-powered devices may collect personal data, raising concerns about how this data is stored and used.': Privacy \n","Category for 'Security vulnerabilities: AI systems could be susceptible to cyberattacks, leading to unauthorized access to personal information.': Security \n","Category for 'Bias in AI algorithms: AI algorithms might inadvertently perpetuate biases present in the data they are trained on, leading to unfair or discriminatory outcomes.': Fairness\n","\n","AI Risks Summary:\n","\n","Category: Privacy \n","- Privacy concerns: AI-powered devices may collect personal data, raising concerns about how this data is stored and used.\n","Category: Security \n","- Security vulnerabilities: AI systems could be susceptible to cyberattacks, leading to unauthorized access to personal information.\n","Category: Fairness\n","- Bias in AI algorithms: AI algorithms might inadvertently perpetuate biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n"]}],"source":["def get_risks_and_categories(risks_list):\n","    \"\"\"\n","    Identify and categorize potential risks of using AI in everyday life.\n","\n","    Parameters:\n","        risks_list (list): A list of potential risks and categories associated with AI usage.\n","\n","    Returns:\n","        list: A list containing categorized risks.\n","    \"\"\"\n","    categories = []\n","\n","    print(\"Welcome to the AI Risks Identification Tool!\")\n","    print(\"Enter the category of each risk:\")\n","\n","    for risk in risks_list:\n","        category = input(f\"Category for '{risk}': \")\n","        categories.append((risk, category))\n","\n","    return categories\n","\n","\n","@test_identify_risks\n","def identify_risks(risks_categories):\n","    \"\"\"\n","    Identify and categorize potential risks of using AI in everyday life.\n","\n","    Parameters:\n","        risks_categories (list): A list of potential risks and categories associated with AI usage.\n","\n","    Returns:\n","        dict: A dictionary containing categorized risks.\n","    \"\"\"\n","    categorized_risks = {}\n","\n","    for risk, category in risks_categories:\n","        if category not in categorized_risks:\n","            categorized_risks[category] = []\n","        categorized_risks[category].append(risk)\n","\n","    return categorized_risks\n","\n","\n","def display_risks_summary(risks):\n","    \"\"\"\n","    Display a summary of identified risks under each category.\n","\n","    Parameters:\n","        risks (dict): A dictionary containing categorized risks.\n","    \"\"\"\n","    print(\"\\nAI Risks Summary:\\n\")\n","\n","    for category, category_risks in risks.items():\n","        print(f\"Category: {category}\")\n","        for risk in category_risks:\n","            print(f\"- {risk}\")\n","\n","\n","risks_list = [\n","    \"Privacy concerns: AI-powered devices may collect personal data, raising concerns about how this data is stored and used.\",\n","    \"Security vulnerabilities: AI systems could be susceptible to cyberattacks, leading to unauthorized access to personal information.\",\n","    \"Bias in AI algorithms: AI algorithms might inadvertently perpetuate biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\",\n","    # Add more AI Risks to this list\n","]\n","\n","risks_categories = get_risks_and_categories(risks_list)\n","risks_data = identify_risks(risks_categories)\n","display_risks_summary(risks_data)\n"]}]}